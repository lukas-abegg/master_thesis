{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Newsela article sentences automatically assigned:\n",
      "------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../data/newsela/newsela_articles.aligned.sents.txt does not exist: '../data/newsela/newsela_articles.aligned.sents.txt'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-2-60059436a4e5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mfilepath_aligned\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnewsela\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfilepath_aligned\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m \u001B[0mdf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_aligned\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msep\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"\\n\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcolumns\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m\"S\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mS\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreplace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mr'\\\\n'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m' '\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mregex\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mparser_f\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    674\u001B[0m         )\n\u001B[1;32m    675\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 676\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    677\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    678\u001B[0m     \u001B[0mparser_f\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__name__\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    446\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    447\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 448\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    449\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    450\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    878\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    879\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 880\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    881\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    882\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1112\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1113\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1114\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1115\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1116\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/anaconda3-2019.10/lib/python3.7/site-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   1889\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1890\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1891\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1892\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1893\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] File ../data/newsela/newsela_articles.aligned.sents.txt does not exist: '../data/newsela/newsela_articles.aligned.sents.txt'"
     ]
    }
   ],
   "source": [
    "newsela = \"../data/newsela\"\n",
    "\n",
    "print(\"Newsela article sentences automatically assigned:\")\n",
    "print(\"------------------------------\")\n",
    "\n",
    "filepath_aligned = 'newsela_articles.aligned.sents.txt'\n",
    "filepath_aligned = os.path.join(newsela, filepath_aligned)\n",
    "\n",
    "df = pd.read_csv(filepath_aligned, header=None, sep=\"\\n\")\n",
    "df.columns = [\"S\"]\n",
    "df.S.replace(r'\\\\n',' ', regex=True)\n",
    "df = df.S.str.split(\"\\t\", expand=True)\n",
    "df.columns = [\"Doc\", \"O_V\", \"T_V\", \"O_T\", \"T_T\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_V0_V1 = df[(df.O_V == \"V0\")&(df.T_V == \"V1\")]\n",
    "df_V0_V2 = df[(df.O_V == \"V0\")&(df.T_V == \"V2\")]\n",
    "df_V0_V3 = df[(df.O_V == \"V0\")&(df.T_V == \"V3\")]\n",
    "df_V0_V4 = df[(df.O_V == \"V0\")&(df.T_V == \"V4\")]\n",
    "\n",
    "df_V1_V2 = df[(df.O_V == \"V1\")&(df.T_V == \"V2\")]\n",
    "df_V1_V3 = df[(df.O_V == \"V1\")&(df.T_V == \"V3\")]\n",
    "df_V1_V4 = df[(df.O_V == \"V1\")&(df.T_V == \"V4\")]\n",
    "\n",
    "df_V2_V3 = df[(df.O_V == \"V2\")&(df.T_V == \"V3\")]\n",
    "df_V2_V4 = df[(df.O_V == \"V2\")&(df.T_V == \"V4\")]\n",
    "\n",
    "df_V3_V4 = df[(df.O_V == \"V3\")&(df.T_V == \"V4\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nV0:\")\n",
    "print(\"***************\")\n",
    "print(len(df_V0_V1))\n",
    "print(len(df_V0_V2))\n",
    "print(len(df_V0_V3))\n",
    "print(len(df_V0_V4))\n",
    "\n",
    "print(\"\\nV1:\")\n",
    "print(\"***************\")\n",
    "print(len(df_V1_V2))\n",
    "print(len(df_V1_V3))\n",
    "print(len(df_V1_V4))\n",
    "\n",
    "print(\"\\nV2:\")\n",
    "print(\"***************\")\n",
    "print(len(df_V2_V3))\n",
    "print(len(df_V2_V4))\n",
    "\n",
    "print(\"\\nV3:\")\n",
    "print(\"***************\")\n",
    "print(len(df_V3_V4))\n",
    "\n",
    "#----------------------\n",
    "\n",
    "print(\"\\nV0-Sum:\")\n",
    "print(\"***************\")\n",
    "print(len(df_V0_V1) + len(df_V0_V2) + len(df_V0_V3) + len(df_V0_V4))\n",
    "\n",
    "print(\"\\nV1-Sum:\")\n",
    "print(\"***************\")\n",
    "print(len(df_V1_V2) + len(df_V1_V3) + len(df_V1_V4))\n",
    "\n",
    "print(\"\\nV2-Sum:\")\n",
    "print(\"***************\")\n",
    "print(len(df_V2_V3) + len(df_V2_V4))\n",
    "\n",
    "print(\"\\nV3-Sum:\")\n",
    "print(\"***************\")\n",
    "print(len(df_V3_V4))\n",
    "\n",
    "#----------------------\n",
    "\n",
    "print(\"\\nSum (V0-V3):\")\n",
    "print(\"***************\")\n",
    "print(len(df_V0_V1) + len(df_V0_V2) + len(df_V0_V3) + len(df_V0_V4) + len(df_V1_V2) + len(df_V1_V3) + len(df_V1_V4) + len(df_V2_V3) + len(df_V2_V4) + len(df_V3_V4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-2e89c7cf9e30>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdf_to_V1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mT_V\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"V1\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"\\nTo V1-Sum:\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"***************\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdf_to_V1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df_to_V1 = df[(df.T_V == \"V1\")]\n",
    "print(\"\\nTo V1-Sum:\")\n",
    "print(\"***************\")\n",
    "print(len(df_to_V1))\n",
    "\n",
    "df_to_V2 = df[(df.T_V == \"V2\")]\n",
    "print(\"\\nTo V2-Sum:\")\n",
    "print(\"***************\")\n",
    "print(len(df_to_V2))\n",
    "\n",
    "df_to_V3 = df[(df.T_V == \"V3\")]\n",
    "print(\"\\nTo V3-Sum:\")\n",
    "print(\"***************\")\n",
    "print(len(df_to_V3))\n",
    "\n",
    "df_to_V4 = df[(df.T_V == \"V4\")]\n",
    "print(\"\\nTo V4-Sum:\")\n",
    "print(\"***************\")\n",
    "print(len(df_to_V4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-5933e31ad5af>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mdocs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDoc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdrop_duplicates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdocs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "docs = df.Doc.drop_duplicates()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_metadata = 'articles_metadata.csv'\n",
    "filepath_metadata = os.path.join(newsela, filepath_metadata)\n",
    "\n",
    "df_metadata = pd.read_csv(filepath_metadata, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 slug language  \\\n",
      "0  10dollarbill-woman       en   \n",
      "1  10dollarbill-woman       en   \n",
      "2  10dollarbill-woman       en   \n",
      "3  10dollarbill-woman       en   \n",
      "4  10dollarbill-woman       en   \n",
      "\n",
      "                                               title  grade_level  version  \\\n",
      "0  Tubman, Perkins or Roosevelt? Woman on $10 bil...         12.0        0   \n",
      "1  Americans weigh in to choose the woman who wil...          8.0        1   \n",
      "2  The $10 question: Who will be the new face on ...          6.0        2   \n",
      "3  New $10 bill will have a theme and a woman's p...          5.0        3   \n",
      "4  We will soon have an American woman's face on ...          3.0        4   \n",
      "\n",
      "                      filename  \n",
      "0  10dollarbill-woman.en.0.txt  \n",
      "1  10dollarbill-woman.en.1.txt  \n",
      "2  10dollarbill-woman.en.2.txt  \n",
      "3  10dollarbill-woman.en.3.txt  \n",
      "4  10dollarbill-woman.en.4.txt  \n",
      "\n",
      "****************\n",
      "\n",
      "Amount of sentences at all: 10786\n",
      "\n",
      "Columns: Index(['slug', 'language', 'title', 'grade_level', 'version', 'filename'], dtype='object')\n",
      "\n",
      "Amount of Sentences: 2154\n",
      "\n",
      "Amount of Sentences V0: 2154\n",
      "\n",
      "Amount of Sentences V1: 2153\n",
      "\n",
      "Amount of Sentences V2: 2153\n",
      "\n",
      "Amount of Sentences V3: 2153\n",
      "\n",
      "Amount of Sentences V4: 2125\n",
      "\n",
      "Amount of Sentences V5: 48\n",
      "\n",
      "Amount of Sentences V6: 0\n",
      "\n",
      "Overall V0-V6: 10786\n"
     ]
    }
   ],
   "source": [
    "print(df_metadata.head())\n",
    "print(\"\\n****************\")\n",
    "print(\"\\nAmount of sentences at all:\", len(df_metadata))\n",
    "print(\"\\nColumns:\", df_metadata.columns)\n",
    "print(\"\\nAmount of Sentences:\", len(df_metadata.slug.drop_duplicates()))\n",
    "print(\"\\nAmount of Sentences V0:\", len(df_metadata[(df_metadata.version == 0)]))\n",
    "print(\"\\nAmount of Sentences V1:\", len(df_metadata[(df_metadata.version == 1)]))\n",
    "print(\"\\nAmount of Sentences V2:\", len(df_metadata[(df_metadata.version == 2)]))\n",
    "print(\"\\nAmount of Sentences V3:\", len(df_metadata[(df_metadata.version == 3)]))\n",
    "print(\"\\nAmount of Sentences V4:\", len(df_metadata[(df_metadata.version == 4)]))\n",
    "print(\"\\nAmount of Sentences V5:\", len(df_metadata[(df_metadata.version == 5)]))\n",
    "print(\"\\nAmount of Sentences V6:\", len(df_metadata[(df_metadata.version == 6)]))\n",
    "print(\"\\nOverall V0-V6:\", len(df_metadata[df_metadata.version.isin([0,1,2,3,4,5,6])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_json en 1130\n",
      "df_json es 0\n",
      "df_json length 1130\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category                                    {'name': 'War & Peace'}\n",
       "articles          [{'grade_level': 3.0, 'docid': 8, 'title': 'Wo...\n",
       "language                                                         en\n",
       "tags                                                     [military]\n",
       "image             https://newsela-test-files-f331e.s3.amazonaws....\n",
       "image_caption     Specialist Crisma Albarran detaches an ammunit...\n",
       "date_published                                 2013-03-20T14:26:20Z\n",
       "image_credit                                              U.S. Army\n",
       "slug                                                   combat-women\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "filepath_json = 'newsela_articles.sents.json'\n",
    "filepath_json = os.path.join(newsela, filepath_json)\n",
    "    \n",
    "df_json = pd.read_json(filepath_json)\n",
    "print(\"df_json en\", len(df_json[df_json.language == \"en\"]))\n",
    "print(\"df_json es\", len(df_json[df_json.language == \"es\"]))\n",
    "print(\"df_json length\", len(df_json))\n",
    "df_json.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade_level</th>\n",
       "      <th>docid</th>\n",
       "      <th>title</th>\n",
       "      <th>lexile_level</th>\n",
       "      <th>sentences</th>\n",
       "      <th>is_original</th>\n",
       "      <th>teaser</th>\n",
       "      <th>author_display_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1101</td>\n",
       "      <td>PRO/CON: Will the CIA torture hurt U.S.?</td>\n",
       "      <td>740</td>\n",
       "      <td>[# # # PRO : Report makes more attacks more li...</td>\n",
       "      <td>False</td>\n",
       "      <td>It gives extremists one more reason to attack ...</td>\n",
       "      <td>Tribune News Service and McClatchy, adapted by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1101</td>\n",
       "      <td>PRO/CON: Does the CIA torture report put the U...</td>\n",
       "      <td>890</td>\n",
       "      <td>[# # # PRO : Report leaves U.S. more open to a...</td>\n",
       "      <td>False</td>\n",
       "      <td>The PRO author argues that the report gives a ...</td>\n",
       "      <td>Tribune News Service and McClatchy, adapted by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1101</td>\n",
       "      <td>PRO/CON: Will the CIA torture report put the U...</td>\n",
       "      <td>940</td>\n",
       "      <td>[# # # PRO : Report puts American lives at ris...</td>\n",
       "      <td>False</td>\n",
       "      <td>Extremists will use the report to get more fig...</td>\n",
       "      <td>Tribune News Service and McClatchy, adapted by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1101</td>\n",
       "      <td>PRO/CON: Does the CIA torture report hurt the ...</td>\n",
       "      <td>1100</td>\n",
       "      <td>[# # # PRO : Report gives extremists a rallyin...</td>\n",
       "      <td>False</td>\n",
       "      <td>The report gives ammunition to extremist group...</td>\n",
       "      <td>Tribune News Service and McClatchy, adapted by...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.0</td>\n",
       "      <td>1101</td>\n",
       "      <td>PRO/CON: Will the release of the CIA torture r...</td>\n",
       "      <td>1360</td>\n",
       "      <td>[# # # PRO : CIA report encourages extremists ...</td>\n",
       "      <td>True</td>\n",
       "      <td>The PRO writer argues that the report will act...</td>\n",
       "      <td>Lawrence J. Haas, Tribune News Service, and Jo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   grade_level  docid                                              title  \\\n",
       "0          5.0   1101           PRO/CON: Will the CIA torture hurt U.S.?   \n",
       "1          6.0   1101  PRO/CON: Does the CIA torture report put the U...   \n",
       "2          7.0   1101  PRO/CON: Will the CIA torture report put the U...   \n",
       "3          9.0   1101  PRO/CON: Does the CIA torture report hurt the ...   \n",
       "4         12.0   1101  PRO/CON: Will the release of the CIA torture r...   \n",
       "\n",
       "   lexile_level                                          sentences  \\\n",
       "0           740  [# # # PRO : Report makes more attacks more li...   \n",
       "1           890  [# # # PRO : Report leaves U.S. more open to a...   \n",
       "2           940  [# # # PRO : Report puts American lives at ris...   \n",
       "3          1100  [# # # PRO : Report gives extremists a rallyin...   \n",
       "4          1360  [# # # PRO : CIA report encourages extremists ...   \n",
       "\n",
       "   is_original                                             teaser  \\\n",
       "0        False  It gives extremists one more reason to attack ...   \n",
       "1        False  The PRO author argues that the report gives a ...   \n",
       "2        False  Extremists will use the report to get more fig...   \n",
       "3        False  The report gives ammunition to extremist group...   \n",
       "4         True  The PRO writer argues that the report will act...   \n",
       "\n",
       "                                 author_display_name  \n",
       "0  Tribune News Service and McClatchy, adapted by...  \n",
       "1  Tribune News Service and McClatchy, adapted by...  \n",
       "2  Tribune News Service and McClatchy, adapted by...  \n",
       "3  Tribune News Service and McClatchy, adapted by...  \n",
       "4  Lawrence J. Haas, Tribune News Service, and Jo...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import json_normalize\n",
    "json_normalize(df_json.articles.iloc[1029])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}